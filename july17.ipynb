{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2990a846-10c8-45de-992e-cc25c8fe2dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spacy is object oriented\n",
    "# nltk is string oriented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6eb77a9e-bcfa-4590-b755-a4f823f8340b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.1.3 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"/opt/anaconda3/lib/python3.12/runpy.py\", line 198, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/anaconda3/lib/python3.12/runpy.py\", line 88, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/ipykernel/kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/tornado/platform/asyncio.py\", line 211, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/opt/anaconda3/lib/python3.12/asyncio/base_events.py\", line 641, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/opt/anaconda3/lib/python3.12/asyncio/base_events.py\", line 1986, in _run_once\n",
      "    handle._run()\n",
      "  File \"/opt/anaconda3/lib/python3.12/asyncio/events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3075, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3130, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3334, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3517, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3577, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/var/folders/lh/p4vn7c1j3gz_7jnnl5ph5rzm0000gn/T/ipykernel_27978/572880994.py\", line 1, in <module>\n",
      "    import spacy\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/spacy/__init__.py\", line 6, in <module>\n",
      "    from .errors import setup_default_warnings\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/spacy/errors.py\", line 3, in <module>\n",
      "    from .compat import Literal\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/spacy/compat.py\", line 4, in <module>\n",
      "    from thinc.util import copy_array\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/thinc/__init__.py\", line 5, in <module>\n",
      "    from .config import registry\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/thinc/config.py\", line 5, in <module>\n",
      "    from .types import Decorator\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/thinc/types.py\", line 27, in <module>\n",
      "    from .compat import cupy, has_cupy\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/thinc/compat.py\", line 35, in <module>\n",
      "    import torch\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/torch/__init__.py\", line 1471, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/torch/functional.py\", line 9, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/torch/nn/__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "/opt/anaconda3/lib/python3.12/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n"
     ]
    }
   ],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3eccf4d9-6e18-4dcc-9f10-e58763aa8a92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dr. told me so and I love myself.\n",
      "It was quite challenging, but I did it!\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "doc = nlp(\"The dr. told me so and I love myself. It was quite challenging, but I did it!\")\n",
    "\n",
    "for sentence in doc.sents:\n",
    "    print(sentence) # splits two sentences accurately!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "edd66bd8-8946-4664-a333-23f309626b59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The\n",
      "dr\n",
      ".\n",
      "told\n",
      "me\n",
      "so\n",
      "and\n",
      "I\n",
      "love\n",
      "myself\n",
      ".\n",
      "It\n",
      "was\n",
      "quite\n",
      "challenging\n",
      ",\n",
      "but\n",
      "I\n",
      "did\n",
      "it\n",
      "!\n"
     ]
    }
   ],
   "source": [
    "for sentence in doc.sents: # word tokenization in spacy\n",
    "    for word in sentence:\n",
    "        print(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d3f4fb9-6934-4b6b-8f68-f40172ac0550",
   "metadata": {},
   "source": [
    "- spacy provides the most efficient NLP algorithm for a given task. if you care about the end result, go with spacy.\n",
    "- nltk provides access to many algorithms, if you care about specific algo and customizations, choose nltk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3503a18f-0347-4d84-b14d-424bfa393123",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The dr. told me so and I love myself.',\n",
       " 'It was quite challenging, but I did it!']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "sent_tokenize(\"The dr. told me so and I love myself. It was quite challenging, but I did it!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "83f6c938-398d-4f0c-aa73-deb2677c1625",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merhabalar\n",
      "!\n",
      "Benim\n",
      "adım\n",
      "Hasan\n",
      "Can\n",
      "Bıyık\n",
      ".\n",
      "Ben\n",
      "harikayım\n",
      ":\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# creating a language object\n",
    "\n",
    "nlp = spacy.blank(\"tr\") # you can use en or other langs\n",
    "\n",
    "doc = nlp(\"Merhabalar! Benim adım Hasan Can Bıyık. Ben harikayım :)\")\n",
    "\n",
    "for token in doc:\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c3cc1dc9-058c-4e34-997b-dc5b834bfca1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Merhabalar"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "04e4c97c-d492-44d8-be69-3fede183b170",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'\n",
      "Let\n",
      "'s\n",
      "go\n",
      "to\n",
      "N.Y.\n",
      "!\n",
      "'\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"\"\"'Let's go to N.Y.!'\"\"\")\n",
    "\n",
    "for token in doc:\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b4535c71-f164-46bf-a173-84c1571d902c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.tokens.token.Token"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "df4e4781-d757-493a-86ca-9eb956fca85f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Let's go to"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc[1:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8878c626-9440-44e2-9609-9dbbdb9322cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Let"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token0 = doc[1]\n",
    "token0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1c705541-cc24-4f6c-9f49-b678a210b45f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_',\n",
       " '__bytes__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__len__',\n",
       " '__lt__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__pyx_vtable__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__unicode__',\n",
       " 'ancestors',\n",
       " 'check_flag',\n",
       " 'children',\n",
       " 'cluster',\n",
       " 'conjuncts',\n",
       " 'dep',\n",
       " 'dep_',\n",
       " 'doc',\n",
       " 'ent_id',\n",
       " 'ent_id_',\n",
       " 'ent_iob',\n",
       " 'ent_iob_',\n",
       " 'ent_kb_id',\n",
       " 'ent_kb_id_',\n",
       " 'ent_type',\n",
       " 'ent_type_',\n",
       " 'get_extension',\n",
       " 'has_dep',\n",
       " 'has_extension',\n",
       " 'has_head',\n",
       " 'has_morph',\n",
       " 'has_vector',\n",
       " 'head',\n",
       " 'i',\n",
       " 'idx',\n",
       " 'iob_strings',\n",
       " 'is_alpha',\n",
       " 'is_ancestor',\n",
       " 'is_ascii',\n",
       " 'is_bracket',\n",
       " 'is_currency',\n",
       " 'is_digit',\n",
       " 'is_left_punct',\n",
       " 'is_lower',\n",
       " 'is_oov',\n",
       " 'is_punct',\n",
       " 'is_quote',\n",
       " 'is_right_punct',\n",
       " 'is_sent_end',\n",
       " 'is_sent_start',\n",
       " 'is_space',\n",
       " 'is_stop',\n",
       " 'is_title',\n",
       " 'is_upper',\n",
       " 'lang',\n",
       " 'lang_',\n",
       " 'left_edge',\n",
       " 'lefts',\n",
       " 'lemma',\n",
       " 'lemma_',\n",
       " 'lex',\n",
       " 'lex_id',\n",
       " 'like_email',\n",
       " 'like_num',\n",
       " 'like_url',\n",
       " 'lower',\n",
       " 'lower_',\n",
       " 'morph',\n",
       " 'n_lefts',\n",
       " 'n_rights',\n",
       " 'nbor',\n",
       " 'norm',\n",
       " 'norm_',\n",
       " 'orth',\n",
       " 'orth_',\n",
       " 'pos',\n",
       " 'pos_',\n",
       " 'prefix',\n",
       " 'prefix_',\n",
       " 'prob',\n",
       " 'rank',\n",
       " 'remove_extension',\n",
       " 'right_edge',\n",
       " 'rights',\n",
       " 'sent',\n",
       " 'sent_start',\n",
       " 'sentiment',\n",
       " 'set_extension',\n",
       " 'set_morph',\n",
       " 'shape',\n",
       " 'shape_',\n",
       " 'similarity',\n",
       " 'subtree',\n",
       " 'suffix',\n",
       " 'suffix_',\n",
       " 'tag',\n",
       " 'tag_',\n",
       " 'tensor',\n",
       " 'text',\n",
       " 'text_with_ws',\n",
       " 'vector',\n",
       " 'vector_norm',\n",
       " 'vocab',\n",
       " 'whitespace_']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(token0) # dir helps getting all the methods of that class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ad06cb-16e4-455f-bc85-38b392fb4e6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "135ca81f-ce46-4055-b41e-b68837a4652f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.tokens.token.Token"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(token0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fb07f13b-7b18-4b55-9db3-f08e2bf13f82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token0.is_alpha # because it is alphabetic, a word, not a number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7ee61b9f-0f69-4e20-bc28-9436f59d85aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token0.like_num # because it is not a number."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6c69c55-8942-40e9-b566-09e80d103bcf",
   "metadata": {},
   "source": [
    "# spacy is more convenient than regular expressions to grab emails\n",
    "\n",
    "with open() as f:\n",
    "    text = f.readlines() # reads all the lines as an array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0a70138a-8753-4637-831a-bb4b52c7ed29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Dayton high school, 8th grade students information\\n',\n",
       " '==================================================\\n',\n",
       " '\\n',\n",
       " 'Name\\tbirth day   \\temail\\n',\n",
       " '-----\\t------------\\t------\\n',\n",
       " 'Virat   5 June, 1882    virat@kohli.com\\n',\n",
       " 'Maria\\t12 April, 2001  maria@sharapova.com\\n',\n",
       " 'Serena  24 June, 1998   serena@williams.com \\n',\n",
       " 'Joe      1 May, 1997    joe@root.com\\n',\n",
       " '\\n',\n",
       " '\\n',\n",
       " '\\n']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"/Users/hasancan/Downloads/students.txt\") as f:\n",
    "    text = f.readlines()\n",
    "text # reads as an array, all the lines!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8a0b9a95-ddb8-4841-8216-3d732b8d4b38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Dayton high school, 8th grade students information\\n ==================================================\\n \\n Name\\tbirth day   \\temail\\n -----\\t------------\\t------\\n Virat   5 June, 1882    virat@kohli.com\\n Maria\\t12 April, 2001  maria@sharapova.com\\n Serena  24 June, 1998   serena@williams.com \\n Joe      1 May, 1997    joe@root.com\\n \\n \\n \\n'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Spacy texts single texts, so I will convert this to a big text.\n",
    "\n",
    "text = ' '.join(text) # seperate by space, text is an array, and join the elements and use space as a delimeter\n",
    "text # created one single sentence!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6327fc96-ee94-4784-8326-2bd304514142",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['virat@kohli.com',\n",
       " 'maria@sharapova.com',\n",
       " 'serena@williams.com',\n",
       " 'joe@root.com']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = nlp(text)\n",
    "\n",
    "emails = [] # we created an empty list to store them!\n",
    "\n",
    "for token in doc:\n",
    "    if token.like_email:\n",
    "        emails.append(token.text)\n",
    "\n",
    "emails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "aa516de0-d84c-4262-a5e9-88a7adea5ed4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merhaba a currency:  False /a number:  False /a word:  True\n",
      "! a currency:  False /a number:  False /a word:  False\n",
      "Ben a currency:  False /a number:  False /a word:  True\n",
      "Dr. a currency:  False /a number:  False /a word:  False\n",
      "Bıyık a currency:  False /a number:  False /a word:  True\n",
      "ve a currency:  False /a number:  False /a word:  True\n",
      "bugün a currency:  False /a number:  False /a word:  True\n",
      "size a currency:  False /a number:  False /a word:  True\n",
      "ben a currency:  False /a number:  False /a word:  True\n",
      "yardımcı a currency:  False /a number:  False /a word:  True\n",
      "olacağım a currency:  False /a number:  False /a word:  True\n",
      ", a currency:  False /a number:  False /a word:  False\n",
      "eğiteceğim a currency:  False /a number:  False /a word:  True\n",
      "! a currency:  False /a number:  False /a word:  False\n",
      "! a currency:  False /a number:  False /a word:  False\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.blank('tr')\n",
    "\n",
    "doc = nlp(\"Merhaba! Ben Dr. Bıyık ve bugün size ben yardımcı olacağım, eğiteceğim!!\")\n",
    "\n",
    "for token in doc:\n",
    "    print(token, 'a currency: ', token.is_currency, '/a number: ', token.like_num, '/a word: ', token.is_alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "fe8186b7-eb59-4918-a970-98b9f047eed8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gim', 'me', 'double', 'cheese', 'extra', 'large', 'pizza']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from spacy.symbols import ORTH\n",
    "\n",
    "nlp.tokenizer.add_special_case('gimme', [\n",
    "    {ORTH: 'gim'},\n",
    "    {ORTH: 'me'}])\n",
    "\n",
    "doc = nlp(\"gimme double cheese extra large pizza\")\n",
    "tokens = [token.text for token in doc]\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a4c5e202-48b0-4922-8534-51601f3647d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.pipe_names # the pipeline is blank!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "66bd2298-658d-4e77-a379-da3604f73ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can also load a pre-trained pipeline!\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1f7d887b-f36f-41c8-9557-f778d890cb44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('tok2vec', <spacy.pipeline.tok2vec.Tok2Vec at 0x3271ca630>),\n",
       " ('tagger', <spacy.pipeline.tagger.Tagger at 0x3271caed0>),\n",
       " ('parser', <spacy.pipeline.dep_parser.DependencyParser at 0x3271dc5f0>),\n",
       " ('attribute_ruler',\n",
       "  <spacy.pipeline.attributeruler.AttributeRuler at 0x3172c6090>),\n",
       " ('lemmatizer', <spacy.lang.en.lemmatizer.EnglishLemmatizer at 0x16c954b50>),\n",
       " ('ner', <spacy.pipeline.ner.EntityRecognizer at 0x3271dc660>)]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c6ee49dd-c622-4fc9-b7ea-aa11ebdc51be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "captain  |  PROPN  |  captain\n",
      "america  |  PROPN  |  america\n",
      "ate  |  VERB  |  eat\n",
      "$  |  SYM  |  $\n",
      "100  |  NUM  |  100\n",
      "of  |  ADP  |  of\n",
      "burgers  |  NOUN  |  burger\n",
      ",  |  PUNCT  |  ,\n",
      "then  |  ADV  |  then\n",
      "he  |  PRON  |  he\n",
      "said  |  VERB  |  say\n",
      "he  |  PRON  |  he\n",
      "can  |  AUX  |  can\n",
      "do  |  VERB  |  do\n",
      "this  |  PRON  |  this\n",
      "all  |  DET  |  all\n",
      "day  |  NOUN  |  day\n",
      "long  |  ADV  |  long\n",
      "!  |  PUNCT  |  !\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"captain america ate $100 of burgers, then he said he can do this all day long!\")\n",
    "\n",
    "for token in doc:\n",
    "    print(token, \" | \", token.pos_, \" | \", token.lemma_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b63a4f38-506e-4bd8-9fae-ca7490f817bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a98361-a734-45bb-9043-3860b9b9f81c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b3b320-4a85-4ba6-8192-ceac982cad6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9041d2ed-dfe7-4f9a-91b6-fe98bbcac6c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
